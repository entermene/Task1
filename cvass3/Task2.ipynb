{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import scipy\n",
    "from skimage import transform\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the RGB images\n",
    "mountain1_img = cv2.imread('Task2/images/mountain1.jpg')\n",
    "mountain2_img = cv2.imread('Task2/images/mountain2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def homography(u1, v1, u2, v2):\n",
    "    # Construct the matrix A\n",
    "    A = []\n",
    "    for i in range(len(u1)):\n",
    "        A.append([-u1[i], -v1[i], -1, 0, 0, 0, u1[i]*u2[i], v1[i]*u2[i], u2[i]])\n",
    "        A.append([0, 0, 0, -u1[i], -v1[i], -1, u1[i]*v2[i], v1[i]*v2[i], v2[i]])\n",
    "\n",
    "    A = np.asarray(A)\n",
    "\n",
    "    # Singular Value Decomposition (SVD) of A\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "\n",
    "    # The homography matrix is the last column of V\n",
    "    H = V[-1].reshape(3, 3)\n",
    "\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_normalisation_matrix(points):\n",
    "    \"\"\"\n",
    "    Compute normalisation matrix for homogeneous point coordinates.\n",
    "\n",
    "    Arguments:\n",
    "    points: numpy array of shape (n, 3) containing homogeneous point coordinates\n",
    "\n",
    "    Returns:\n",
    "    T: normalisation matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate mean of x and y coordinates\n",
    "    mean_x = np.mean(points[:, 0])\n",
    "    mean_y = np.mean(points[:, 1])\n",
    "\n",
    "    # Calculate scale factor\n",
    "    dist_mean = np.sqrt((points[:, 0] - mean_x) ** 2 + (points[:, 1] - mean_y) ** 2)\n",
    "    mean_dist = np.mean(dist_mean)\n",
    "    scale = np.sqrt(2) / mean_dist\n",
    "\n",
    "    # Create normalisation matrix\n",
    "    T = np.array([[scale, 0, -scale * mean_x],\n",
    "                  [0, scale, -scale * mean_y],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "    return T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography_w_normalisation(u1, v1, u2, v2):\n",
    "    \"\"\"\n",
    "    Compute homography matrix with normalisation.\n",
    "\n",
    "    Arguments:\n",
    "    u1, v1: normalised (u,v) coordinates from image 1\n",
    "    u2, v2: normalised (u,v) coordinates from image 2\n",
    "\n",
    "    Returns:\n",
    "    H: the 3×3 homography matrix that warps unnormalised coordinates from image 1 into\n",
    "    unnormalised coordinates from image 2\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert coordinates to homogeneous form\n",
    "    points1 = np.column_stack((u1, v1, np.ones_like(u1)))\n",
    "    points2 = np.column_stack((u2, v2, np.ones_like(u2)))\n",
    "\n",
    "    # Compute normalisation matrices\n",
    "    T1 = compute_normalisation_matrix(points1)\n",
    "    T2 = compute_normalisation_matrix(points2)\n",
    "\n",
    "    # Apply normalisation to points\n",
    "    norm_points1 = np.dot(points1, T1.T)\n",
    "    norm_points2 = np.dot(points2, T2.T)\n",
    "\n",
    "    # Apply DLT algorithm to estimate homography matrix\n",
    "    H_norm = homography(norm_points1[:, 0], norm_points1[:, 1], norm_points2[:, 0], norm_points2[:, 1])\n",
    "\n",
    "    # Denormalise H\n",
    "    H = np.dot(np.linalg.inv(T2), np.dot(H_norm, T1))\n",
    "\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homography matrix with normalisation:\n",
      "[[1.   0.   0.05]\n",
      " [0.   1.   0.05]\n",
      " [0.   0.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def homography(u1, v1, u2, v2):\n",
    "    \"\"\"\n",
    "    Dummy function for estimating homography matrix.\n",
    "    This function needs to be replaced with the actual implementation.\n",
    "    \"\"\"\n",
    "    # Dummy homography matrix for testing\n",
    "    return np.array([[1, 0, 0],\n",
    "                     [0, 1, 0],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "# Define the compute_normalisation_matrix function\n",
    "def compute_normalisation_matrix(points):\n",
    "    \"\"\"\n",
    "    Compute normalisation matrix for homogeneous point coordinates.\n",
    "\n",
    "    Arguments:\n",
    "    points: numpy array of shape (n, 3) containing homogeneous point coordinates\n",
    "\n",
    "    Returns:\n",
    "    T: normalisation matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate mean of x and y coordinates\n",
    "    mean_x = np.mean(points[:, 0])\n",
    "    mean_y = np.mean(points[:, 1])\n",
    "\n",
    "    # Calculate scale factor\n",
    "    dist_mean = np.sqrt((points[:, 0] - mean_x) ** 2 + (points[:, 1] - mean_y) ** 2)\n",
    "    mean_dist = np.mean(dist_mean)\n",
    "    scale = np.sqrt(2) / mean_dist\n",
    "\n",
    "    # Create normalisation matrix\n",
    "    T = np.array([[scale, 0, -scale * mean_x],\n",
    "                  [0, scale, -scale * mean_y],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "    return T\n",
    "\n",
    "# Define the homography_w_normalisation function\n",
    "def homography_w_normalisation(u1, v1, u2, v2):\n",
    "    \"\"\"\n",
    "    Compute homography matrix with normalisation.\n",
    "\n",
    "    Arguments:\n",
    "    u1, v1: normalised (u,v) coordinates from image 1\n",
    "    u2, v2: normalised (u,v) coordinates from image 2\n",
    "\n",
    "    Returns:\n",
    "    H: the 3×3 homography matrix that warps unnormalised coordinates from image 1 into\n",
    "    unnormalised coordinates from image 2\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert coordinates to homogeneous form\n",
    "    points1 = np.column_stack((u1, v1, np.ones_like(u1)))\n",
    "    points2 = np.column_stack((u2, v2, np.ones_like(u2)))\n",
    "\n",
    "    # Compute normalisation matrices\n",
    "    T1 = compute_normalisation_matrix(points1)\n",
    "    T2 = compute_normalisation_matrix(points2)\n",
    "\n",
    "    # Apply normalisation to points\n",
    "    norm_points1 = np.dot(points1, T1.T)\n",
    "    norm_points2 = np.dot(points2, T2.T)\n",
    "\n",
    "    # Apply DLT algorithm to estimate homography matrix\n",
    "    H_norm = homography(norm_points1[:, 0], norm_points1[:, 1], norm_points2[:, 0], norm_points2[:, 1])\n",
    "\n",
    "    # Denormalise H\n",
    "    H = np.dot(np.linalg.inv(T2), np.dot(H_norm, T1))\n",
    "\n",
    "    return H\n",
    "\n",
    "# Test the homography_w_normalisation function with sample coordinates\n",
    "u1 = np.array([0.1, 0.2, 0.3])\n",
    "v1 = np.array([0.3, 0.5, 0.8])\n",
    "u2 = np.array([0.15, 0.25, 0.35])\n",
    "v2 = np.array([0.35, 0.55, 0.85])\n",
    "\n",
    "# Calculate homography matrix with normalisation\n",
    "H = homography_w_normalisation(u1, v1, u2, v2)\n",
    "print(\"Homography matrix with normalisation:\")\n",
    "print(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_matching_keypoints(image1, image2):\n",
    "    \"\"\"\n",
    "    Find matching keypoints between two images using SIFT.\n",
    "\n",
    "    Arguments:\n",
    "    image1: numpy array representing the first image\n",
    "    image2: numpy array representing the second image\n",
    "\n",
    "    Returns:\n",
    "    keypoints1, keypoints2: lists of keypoints found in image1 and image2, respectively\n",
    "    matches: list of matching keypoint pairs\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Find keypoints and descriptors\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(image1, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(image2, None)\n",
    "\n",
    "    # Initialize matcher\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Get corresponding keypoints\n",
    "    matched_keypoints1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 2)\n",
    "    matched_keypoints2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 2)\n",
    "\n",
    "    return matched_keypoints1, matched_keypoints2\n",
    "\n",
    "def sample_corresponding_points(keypoints1, keypoints2, seed=42):\n",
    "    \"\"\"\n",
    "    Sample half of the corresponding points and store as .npy files.\n",
    "\n",
    "    Arguments:\n",
    "    keypoints1: numpy array of keypoints from image 1\n",
    "    keypoints2: numpy array of keypoints from image 2\n",
    "    seed: random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    sampled_keypoints1, sampled_keypoints2: sampled corresponding keypoints\n",
    "    \"\"\"\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Sample half of the corresponding points\n",
    "    num_points = min(len(keypoints1), len(keypoints2))\n",
    "    indices = np.random.choice(num_points, size=num_points // 2, replace=False)\n",
    "\n",
    "    # Select sampled keypoints\n",
    "    sampled_keypoints1 = keypoints1[indices]\n",
    "    sampled_keypoints2 = keypoints2[indices]\n",
    "\n",
    "    # Save keypoints as .npy files\n",
    "    np.save('sampled_keypoints1.npy', sampled_keypoints1)\n",
    "    np.save('sampled_keypoints2.npy', sampled_keypoints2)\n",
    "\n",
    "    return sampled_keypoints1, sampled_keypoints2\n",
    "\n",
    "# Load images\n",
    "image1 = cv2.imread('Task2/images/mountain1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "image2 = cv2.imread('Task2/images/mountain2.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "# Find matching keypoints\n",
    "keypoints1, keypoints2 = find_matching_keypoints(image1, image2)\n",
    "\n",
    "# Sample corresponding points and save as .npy files\n",
    "sampled_keypoints1, sampled_keypoints2 = sample_corresponding_points(keypoints1, keypoints2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homography matrix estimated by RANSAC:\n",
      "[[ 5.80530290e-01  1.37622115e-01  2.58412010e+02]\n",
      " [-2.87159724e-01  8.64004025e-01  5.15256161e+01]\n",
      " [-7.45946837e-04 -1.02565007e-04  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def compute_normalisation_matrix(points):\n",
    "    \"\"\"\n",
    "    Compute normalisation matrix for homogeneous point coordinates.\n",
    "\n",
    "    Arguments:\n",
    "    points: numpy array of shape (n, 3) containing homogeneous point coordinates\n",
    "\n",
    "    Returns:\n",
    "    T: normalisation matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate mean of x and y coordinates\n",
    "    mean_x = np.mean(points[:, 0])\n",
    "    mean_y = np.mean(points[:, 1])\n",
    "\n",
    "    # Calculate scale factor\n",
    "    dist_mean = np.sqrt((points[:, 0] - mean_x) ** 2 + (points[:, 1] - mean_y) ** 2)\n",
    "    mean_dist = np.mean(dist_mean)\n",
    "    scale = np.sqrt(2) / mean_dist\n",
    "\n",
    "    # Create normalisation matrix\n",
    "    T = np.array([[scale, 0, -scale * mean_x],\n",
    "                  [0, scale, -scale * mean_y],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "    return T\n",
    "\n",
    "def homography_w_normalisation_ransac(u1, v1, u2, v2, threshold=4, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Estimate homography matrix with normalisation using RANSAC.\n",
    "\n",
    "    Arguments:\n",
    "    u1, v1: normalised (u,v) coordinates from image 1\n",
    "    u2, v2: normalised (u,v) coordinates from image 2\n",
    "    threshold: RANSAC inlier threshold\n",
    "    max_iterations: maximum number of RANSAC iterations\n",
    "\n",
    "    Returns:\n",
    "    H: the 3×3 homography matrix estimated by RANSAC\n",
    "    \"\"\"\n",
    "\n",
    "    best_H = None\n",
    "    max_inliers = 0\n",
    "\n",
    "    # Convert coordinates to homogeneous form\n",
    "    points1 = np.column_stack((u1, v1, np.ones_like(u1)))\n",
    "    points2 = np.column_stack((u2, v2, np.ones_like(u2)))\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Randomly select 4 correspondences\n",
    "        indices = np.random.choice(len(u1), size=4, replace=False)\n",
    "        src_pts = points1[indices, :]\n",
    "        dst_pts = points2[indices, :]\n",
    "\n",
    "        # Compute homography using selected correspondences\n",
    "        H = cv2.findHomography(src_pts[:, :2], dst_pts[:, :2])[0]\n",
    "\n",
    "        # Calculate reprojection error\n",
    "        projected_pts = np.dot(points1, H.T)\n",
    "        projected_pts /= projected_pts[:, 2:]\n",
    "        errors = np.sqrt(np.sum((points2[:, :2] - projected_pts[:, :2]) ** 2, axis=1))\n",
    "\n",
    "        # Count inliers\n",
    "        inliers = np.sum(errors < threshold)\n",
    "\n",
    "        # Update best homography if current model is better\n",
    "        if inliers > max_inliers:\n",
    "            max_inliers = inliers\n",
    "            best_H = H\n",
    "\n",
    "    return best_H\n",
    "\n",
    "# Load sampled keypoints from previous question\n",
    "sampled_keypoints1 = np.load('sampled_keypoints1.npy')\n",
    "sampled_keypoints2 = np.load('sampled_keypoints2.npy')\n",
    "\n",
    "# Perform RANSAC to estimate homography\n",
    "H_ransac = homography_w_normalisation_ransac(sampled_keypoints1[:, 0], sampled_keypoints1[:, 1],\n",
    "                                             sampled_keypoints2[:, 0], sampled_keypoints2[:, 1])\n",
    "\n",
    "print(\"Homography matrix estimated by RANSAC:\")\n",
    "print(H_ransac)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (374,1034,3) into shape (374,517,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m stitched_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((output_height, output_width, \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     36\u001b[0m stitched_image[:mountain2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], :mountain2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m mountain2\n\u001b[1;32m---> 37\u001b[0m \u001b[43mstitched_image\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmountain2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m warped_mountain1\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Display the stitched image\u001b[39;00m\n\u001b[0;32m     40\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStitched Image\u001b[39m\u001b[38;5;124m'\u001b[39m, stitched_image)\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (374,1034,3) into shape (374,517,3)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def warp_image(img, H, output_size):\n",
    "    \"\"\"\n",
    "    Warp an image according to a given homography matrix.\n",
    "\n",
    "    Arguments:\n",
    "    img: input image to be warped\n",
    "    H: homography matrix\n",
    "    output_size: size of the output image (width, height)\n",
    "\n",
    "    Returns:\n",
    "    warped_img: warped image\n",
    "    \"\"\"\n",
    "\n",
    "    # Warp image using given homography\n",
    "    warped_img = cv2.warpPerspective(img, H, output_size)\n",
    "\n",
    "    return warped_img\n",
    "\n",
    "# Load images\n",
    "mountain1 = cv2.imread('Task2/images/mountain1.jpg')\n",
    "mountain2 = cv2.imread('Task2/images/mountain2.jpg')\n",
    "\n",
    "# Compute dimensions for the output image\n",
    "output_width = mountain1.shape[1] + mountain2.shape[1]\n",
    "output_height = max(mountain1.shape[0], mountain2.shape[0])\n",
    "\n",
    "# Compute homography between mountain1 and mountain2\n",
    "H = homography_w_normalisation_ransac(sampled_keypoints1[:, 0], sampled_keypoints1[:, 1],\n",
    "                                       sampled_keypoints2[:, 0], sampled_keypoints2[:, 1])\n",
    "\n",
    "# Warp mountain1 image according to the calculated homography\n",
    "warped_mountain1 = warp_image(mountain1, H, (output_width, output_height))\n",
    "\n",
    "# Stitch warped mountain1 image with mountain2 image\n",
    "stitched_image = np.zeros((output_height, output_width, 3), dtype=np.uint8)\n",
    "stitched_image[:mountain2.shape[0], :mountain2.shape[1]] = mountain2\n",
    "stitched_image[:, mountain2.shape[1]:] = warped_mountain1\n",
    "\n",
    "# Display the stitched image\n",
    "cv2.imshow('Stitched Image', stitched_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 414 is out of bounds for axis 1 with size 374",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 51\u001b[0m\n\u001b[0;32m     47\u001b[0m H \u001b[38;5;241m=\u001b[39m homography_w_normalisation_ransac(sampled_keypoints1[:, \u001b[38;5;241m0\u001b[39m], sampled_keypoints1[:, \u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     48\u001b[0m                                        sampled_keypoints2[:, \u001b[38;5;241m0\u001b[39m], sampled_keypoints2[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Warp mountain1 image according to the calculated homography\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m warped_mountain1 \u001b[38;5;241m=\u001b[39m \u001b[43mwarp_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmountain1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Create an empty canvas for stitching\u001b[39;00m\n\u001b[0;32m     54\u001b[0m stitched_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((output_height, output_width, \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n",
      "Cell \u001b[1;32mIn[13], line 34\u001b[0m, in \u001b[0;36mwarp_image\u001b[1;34m(img, H, output_size)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;66;03m# Check if mapped pixel is within the bounds of the input image\u001b[39;00m\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m src_x \u001b[38;5;241m<\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m src_y \u001b[38;5;241m<\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m     33\u001b[0m             \u001b[38;5;66;03m# Copy pixel value from input image to output image\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m             \u001b[43mwarped_img\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m img[src_y, src_x]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m warped_img\n",
      "\u001b[1;31mIndexError\u001b[0m: index 414 is out of bounds for axis 1 with size 374"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def warp_image(img, H, output_size):\n",
    "    \"\"\"\n",
    "    Warp an image according to a given homography matrix.\n",
    "\n",
    "    Arguments:\n",
    "    img: input image to be warped\n",
    "    H: homography matrix\n",
    "    output_size: size of the output image (width, height)\n",
    "\n",
    "    Returns:\n",
    "    warped_img: warped image\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an empty canvas for the warped image\n",
    "    warped_img = np.zeros(output_size, dtype=img.dtype)\n",
    "\n",
    "    # Invert homography matrix for forward warping\n",
    "    H_inv = np.linalg.inv(H)\n",
    "\n",
    "    # Iterate over each pixel in the output image\n",
    "    for y in range(output_size[1]):\n",
    "        for x in range(output_size[0]):\n",
    "            # Map output pixel back to input pixel using inverse homography\n",
    "            p = np.dot(H_inv, np.array([x, y, 1]))\n",
    "            p = p / p[2]\n",
    "            src_x, src_y = int(p[0]), int(p[1])\n",
    "\n",
    "            # Check if mapped pixel is within the bounds of the input image\n",
    "            if 0 <= src_x < img.shape[1] and 0 <= src_y < img.shape[0]:\n",
    "                # Copy pixel value from input image to output image\n",
    "                warped_img[y, x] = img[src_y, src_x]\n",
    "\n",
    "    return warped_img\n",
    "\n",
    "# Load images\n",
    "mountain1 = cv2.imread('Task2/images/mountain1.jpg')\n",
    "mountain2 = cv2.imread('Task2/images/mountain2.jpg')\n",
    "\n",
    "# Compute dimensions for the output image\n",
    "output_width = mountain1.shape[1] + mountain2.shape[1]\n",
    "output_height = max(mountain1.shape[0], mountain2.shape[0])\n",
    "\n",
    "# Compute homography between mountain1 and mountain2\n",
    "H = homography_w_normalisation_ransac(sampled_keypoints1[:, 0], sampled_keypoints1[:, 1],\n",
    "                                       sampled_keypoints2[:, 0], sampled_keypoints2[:, 1])\n",
    "\n",
    "# Warp mountain1 image according to the calculated homography\n",
    "warped_mountain1 = warp_image(mountain1, H, (output_width, output_height))\n",
    "\n",
    "# Create an empty canvas for stitching\n",
    "stitched_image = np.zeros((output_height, output_width, 3), dtype=np.uint8)\n",
    "\n",
    "# Copy mountain2 image to the left half of the canvas\n",
    "stitched_image[:mountain2.shape[0], :mountain2.shape[1]] = mountain2\n",
    "\n",
    "# Blend warped mountain1 image with the right half of the canvas\n",
    "stitched_image[:, mountain2.shape[1]:] = warped_mountain1[:, :mountain2.shape[1]]\n",
    "\n",
    "# Display the stitched image\n",
    "cv2.imshow('Stitched Image', stitched_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XUDU\\AppData\\Local\\Temp\\ipykernel_29640\\2555800168.py:60: RuntimeWarning: divide by zero encountered in divide\n",
      "  projected_pts /= projected_pts[:, 2:]\n",
      "C:\\Users\\XUDU\\AppData\\Local\\Temp\\ipykernel_29640\\2555800168.py:60: RuntimeWarning: invalid value encountered in divide\n",
      "  projected_pts /= projected_pts[:, 2:]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def warp_image(img, H, output_size):\n",
    "    \"\"\"\n",
    "    Warp an image according to a given homography matrix.\n",
    "\n",
    "    Arguments:\n",
    "    img: input image to be warped\n",
    "    H: homography matrix\n",
    "    output_size: size of the output image (width, height)\n",
    "\n",
    "    Returns:\n",
    "    warped_img: warped image\n",
    "    \"\"\"\n",
    "\n",
    "    # Warp image using given homography\n",
    "    warped_img = cv2.warpPerspective(img, H, output_size)\n",
    "\n",
    "    return warped_img\n",
    "\n",
    "# Load images\n",
    "mountain1 = cv2.imread('Task2/images/mountain1.jpg')\n",
    "mountain2 = cv2.imread('Task2/images/mountain2.jpg')\n",
    "\n",
    "# Compute dimensions for the output image\n",
    "output_width = mountain1.shape[1] + mountain2.shape[1]\n",
    "output_height = max(mountain1.shape[0], mountain2.shape[0])\n",
    "\n",
    "# Compute homography between mountain1 and mountain2\n",
    "H = homography_w_normalisation_ransac(sampled_keypoints1[:, 0], sampled_keypoints1[:, 1],\n",
    "                                       sampled_keypoints2[:, 0], sampled_keypoints2[:, 1])\n",
    "\n",
    "# Warp mountain1 image according to the calculated homography\n",
    "warped_mountain1 = warp_image(mountain1, H, (output_width, output_height))\n",
    "\n",
    "# Create an empty canvas for stitching\n",
    "stitched_image = np.zeros((output_height, output_width, 3), dtype=np.uint8)\n",
    "\n",
    "# Copy mountain2 image to the left half of the canvas\n",
    "stitched_image[:mountain2.shape[0], :mountain2.shape[1]] = mountain2\n",
    "\n",
    "# Blend warped mountain1 image with the right half of the canvas\n",
    "stitched_image[:, mountain2.shape[1]:] = warped_mountain1[:, :mountain2.shape[1]]\n",
    "\n",
    "# Display the stitched image\n",
    "cv2.imshow('Stitched Image', stitched_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click corresponding points on both images. Press 'q' to finish.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'ginput'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m image2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTask2/images/mountain2.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Manually select correspondences\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m correspondences \u001b[38;5;241m=\u001b[39m \u001b[43mselect_correspondences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Extract corresponding points\u001b[39;00m\n\u001b[0;32m     37\u001b[0m points1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([(c[\u001b[38;5;241m0\u001b[39m], c[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m correspondences])\n",
      "Cell \u001b[1;32mIn[15], line 17\u001b[0m, in \u001b[0;36mselect_correspondences\u001b[1;34m(image1, image2)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClick corresponding points on both images. Press \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to finish.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m     point1 \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mginput\u001b[49m(\u001b[38;5;241m1\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m point1:\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'ginput'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "def select_correspondences(image1, image2):\n",
    "    \"\"\"\n",
    "    Manually select matching points from two images.\n",
    "\n",
    "    Arguments:\n",
    "    image1: first image\n",
    "    image2: second image\n",
    "\n",
    "    Returns:\n",
    "    correspondences: list of corresponding points [(x1, y1, x2, y2), ...]\n",
    "    \"\"\"\n",
    "    cv2.imshow('Image 1', image1)\n",
    "    cv2.imshow('Image 2', image2)\n",
    "    correspondences = []\n",
    "    while True:\n",
    "        print(\"Click corresponding points on both images. Press 'q' to finish.\")\n",
    "        point1 = cv2.ginput(1, timeout=-1)\n",
    "        if not point1:\n",
    "            break\n",
    "        point2 = cv2.ginput(1, timeout=-1)\n",
    "        correspondences.append((point1[0][0], point1[0][1], point2[0][0], point2[0][1]))\n",
    "        cv2.circle(image1, (int(point1[0][0]), int(point1[0][1])), 5, (0, 255, 0), -1)\n",
    "        cv2.circle(image2, (int(point2[0][0]), int(point2[0][1])), 5, (0, 255, 0), -1)\n",
    "        cv2.imshow('Image 1', image1)\n",
    "        cv2.imshow('Image 2', image2)\n",
    "    cv2.destroyAllWindows()\n",
    "    return correspondences\n",
    "\n",
    "# Load images\n",
    "image1 = cv2.imread('Task2/images/mountain1.jpg')\n",
    "image2 = cv2.imread('Task2/images/mountain2.jpg')\n",
    "\n",
    "# Manually select correspondences\n",
    "correspondences = select_correspondences(image1.copy(), image2.copy())\n",
    "\n",
    "# Extract corresponding points\n",
    "points1 = np.array([(c[0], c[1], 1) for c in correspondences])\n",
    "points2 = np.array([(c[2], c[3], 1) for c in correspondences])\n",
    "\n",
    "# Calculate homography matrix\n",
    "H = homography_w_normalisation(points1[:, 0], points1[:, 1], points2[:, 0], points2[:, 1])\n",
    "\n",
    "# Use H for rectification or further analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rectified results, achieved through methods like homography transformation, can be influenced by various factors both theoretically and empirically. Let's discuss them:\n",
    "\n",
    "Theoretical Factors:\n",
    "Accuracy of Correspondences: The accuracy of correspondences between images directly affects the quality of rectified results. If the correspondences are inaccurate or contain outliers, the estimated homography matrix will be incorrect, leading to distorted rectified images.\n",
    "Homography Estimation Method: The method used to estimate the homography matrix also plays a significant role. Different algorithms, like Direct Linear Transformation (DLT) or RANSAC, have different strengths and weaknesses in handling noise, outliers, and geometric transformations, which can affect the rectified results.\n",
    "Choice of Normalisation: The normalisation step in homography estimation helps in stabilising the computation and improving the accuracy of the estimated matrix. However, the choice of normalisation method can affect the final rectified results.\n",
    "Empirical Factors:\n",
    "Quality of Feature Detection and Matching: The accuracy and robustness of feature detection and matching algorithms, such as SIFT or SURF, impact the quality of correspondences. Higher quality correspondences lead to better rectified results.\n",
    "Homography Model Assumptions: The homography model assumes a planar scene and a pinhole camera model. Deviations from these assumptions, such as non-planar scenes or lens distortion, can affect the accuracy of rectified results.\n",
    "Image Distortions: Distortions present in the input images, such as lens distortion or perspective distortions, can impact the accuracy of homography estimation and subsequently affect the rectified results.\n",
    "Noise and Occlusions: Noise in the images and occlusions in the scene can introduce errors in feature detection and matching, leading to inaccuracies in homography estimation and rectified results.\n",
    "To empirically assess the rectified results, one can manually select ground-truth correspondences between images and use functions like homography_w_normalisation to calculate the homography matrix. Comparing the rectified images obtained using the estimated homography with the ground truth can provide insights into the accuracy and effectiveness of the rectification process. Additionally, quantitative metrics such as reprojection error or visual inspection can be used to evaluate the rectified results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonfocv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
